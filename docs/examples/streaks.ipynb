{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4568ec08",
   "metadata": {},
   "source": [
    "# Streaks analysis\n",
    "\n",
    "\n",
    "Streaks analysis is done by [Koch (20004)](https://www.climate-service-center.de/imperia/md/content/gkss/institut_fuer_kuestenforschung/ksd/paper/kochw_ieee_2004.pdf) algorithm implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5a0730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed modules\n",
    "import xsar\n",
    "import xsarsea\n",
    "import xsarsea.gradients\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import time\n",
    "\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "import geoviews as gv\n",
    "from holoviews.operation.datashader import rasterize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ea79fe-2816-4d74-b201-095370f3aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional debug messages\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger('xsarsea.gradients').setLevel(logging.INFO) # or .setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe38d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a file a 100m \n",
    "filename = xsar.get_test_file('S1A_IW_GRDH_1SDV_20170907T103020_20170907T103045_018268_01EB76_Z010.SAFE') # irma\n",
    "#filename = xsar.get_test_file('S1B_IW_GRDH_1SDV_20181013T062322_20181013T062347_013130_018428_Z000.SAFE') # bz\n",
    "#filename=xsar.get_test_file('S1B_IW_GRDH_1SDV_20211024T051203_20211024T051228_029273_037E47_Z010.SAFE') # nices streaks\n",
    "#filename=xsar.get_test_file('S1A_IW_GRDH_1SDV_20170720T112706_20170720T112735_017554_01D5C2_Z010.SAFE') # subswath\n",
    "#filename = '/home/oarcher/SAFE/S1A_EW_GRDM_1SDV_20181009T234410_20181009T234510_024066_02A153_DB9C.SAFE'\n",
    "sar_ds = xsar.open_dataset(filename,resolution='100m').isel(line=slice(20,None,None),sample=slice(20,None,None)) # isel to skip bad image edge\n",
    "\n",
    "# add detrended sigma0\n",
    "sar_ds['sigma0_detrend'] = xsarsea.sigma0_detrend(sar_ds.sigma0, sar_ds.incidence)\n",
    "# apply land mask\n",
    "land_mask = sar_ds['land_mask'].compute()\n",
    "sar_ds['sigma0_detrend'] = xr.where(land_mask, np.nan, sar_ds['sigma0_detrend']).transpose(*sar_ds['sigma0_detrend'].dims).compute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52d26e",
   "metadata": {},
   "source": [
    "## General overview\n",
    "\n",
    "Gradients direction analysis is done by moving a window over the image. [xsarsea.gradients.Gradients](../basic_api.rst#xsarsea.gradients.Gradients) allow multiple windows sizes and resolutions.\n",
    "\n",
    "`sar_ds` is a IW_GRDH SAFE with a pixel size of 10m at full resolution. So to compute compute gradients with windows size of 16km and 32km, we need to use `windows_sizes=[1600,3200]`\n",
    "\n",
    "`sar_ds` resolution is 100m, so if we want to compute gradients at 100m an 200m, we need to use `downscales_factors=[1,2]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e0a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = xsarsea.gradients.Gradients(sar_ds['sigma0_detrend'], windows_sizes=[1600,3200], downscales_factors=[1,2])\n",
    "#gradients = xsarsea.gradients.Gradients(sar_ds['sigma0_detrend'], windows_sizes=[400,800], downscales_factors=[1,2])\n",
    "\n",
    "# get gradients histograms as an xarray dataset\n",
    "hist = gradients.histogram\n",
    "\n",
    "# get orthogonals gradients\n",
    "hist['angles'] = hist['angles'] + np.pi/2\n",
    "\n",
    "#mean\n",
    "hist_mean = hist.mean(['downscale_factor','window_size','pol'])\n",
    "\n",
    "# mean, and smooth\n",
    "hist_mean_smooth = hist_mean.copy()\n",
    "hist_mean_smooth['weight'] = xsarsea.gradients.circ_smooth(hist_mean_smooth['weight'])\n",
    "\n",
    "# smooth only\n",
    "hist_smooth = hist.copy()\n",
    "hist_smooth['weight'] = xsarsea.gradients.circ_smooth(hist_smooth['weight'])\n",
    "\n",
    "# select histogram peak\n",
    "iangle = hist_mean_smooth['weight'].fillna(0).argmax(dim='angles')\n",
    "streaks_dir = hist_mean_smooth.angles.isel(angles=iangle)\n",
    "streaks_weight = hist_mean_smooth['weight'].isel(angles=iangle)\n",
    "streaks = xr.merge([dict(angle=streaks_dir,weight=streaks_weight)]).drop('angles')\n",
    "\n",
    "\n",
    "# convert from image convention (rad=0=line) to geographic convention (deg=0=north)\n",
    "# select needed variables in original dataset, and map them to streaks dataset\n",
    "streaks_geo = sar_ds[['longitude','latitude','ground_heading']].interp(\n",
    "    line=streaks.line,\n",
    "    sample=streaks.sample, \n",
    "    method='nearest')\n",
    "\n",
    "streaks_geo['weight'] = streaks['weight']\n",
    "\n",
    "# convert directions from image convention to geographic convention\n",
    "streaks_geo['streaks_dir'] =  xsarsea.dir_sample_to_geo(streaks['angle'], streaks_geo['ground_heading']) \n",
    "\n",
    "streaks_geo = streaks_geo.compute()\n",
    "\n",
    "# plot. Note that hv.VectorField only accept radians, and 0 is West, so we need to reconvert degrees to radians when calling ...\n",
    "gv.tile_sources.Wikipedia * gv.VectorField(\n",
    "    (\n",
    "        streaks_geo['longitude'], \n",
    "        streaks_geo['latitude'], \n",
    "        np.pi/2 -np.deg2rad(streaks_geo['streaks_dir']), \n",
    "        streaks_geo['weight']\n",
    "    )\n",
    ").opts(pivot='mid', arrow_heads=False, tools=['hover'], magnitude='Magnitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c9ff4b",
   "metadata": {},
   "source": [
    "> **_WARNING:_**  `hv.VectorField` and `gv.VectorField` don't use degrees north convention, but radian convention, with 0 = East or right\n",
    "> So, to use them with degrees north, you have to convert them to gradients with \n",
    "> ```python\n",
    "> np.pi/2 -np.deg2rad(deg_north)\n",
    "> ```\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76c35e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Digging into intermediate computations \n",
    "\n",
    "### streaks_geo\n",
    "\n",
    "`streaks_geo` is a `xarray.Dataset`, with `latitude`, `longitude` and `streaks_dir` (0=deg north) variables.\n",
    "\n",
    "It has dims `('line', 'sample')`, with a spacing corresponding to the first windows size, according to the window step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db64e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaks_geo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5001ec04",
   "metadata": {},
   "source": [
    "### streaks\n",
    "\n",
    "`streaks_geo` was computed from `streaks` (also a `xarray.Dataset`). The main difference is that the `angle` variable from `streaks` is in radians, in *image convention* (ie rad=0 is in sample direction) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f3ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c42c677",
   "metadata": {},
   "source": [
    "#### Convertion between image convention and geographic convention\n",
    "\n",
    "see [xsarsea.dir_geo_to_sample](../basic_api.rst#xsarsea.dir_geo_to_sample) and [xsarsea.dir_sample_to_geo](../basic_api.rst#xsarsea.dir_sample_to_geo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72f3b5a",
   "metadata": {},
   "source": [
    "### hist_mean\n",
    "\n",
    "`streaks` variable was computed from `hist_mean_smooth`.\n",
    "\n",
    "The main difference with `streaks` variable is that we don't have a single angle, but a histogram of probability for binned angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb19085",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_mean_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dc02d0",
   "metadata": {},
   "source": [
    "Let's exctract one histogram at an arbitrary position, and plot the histogram.\n",
    "\n",
    "We can do this with the regular `hv.Histogram` function, or use [xsarsea.gradients.circ_hist](../basic_api.rst#xsarsea.gradients.circ_hist), that might be used with `hv.Path` to plot the histogram as a circular one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d504e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_at = hist_mean_smooth['weight'].sel(line=5000,sample=12000,method='nearest')\n",
    "hv.Histogram( (hist_at.angles, hist_at )) + hv.Path(xsarsea.gradients.circ_hist(hist_at))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0ee5f7",
   "metadata": {},
   "source": [
    "`xsarsea` also provide an interactive drawing class [xsarsea.gradients.PlotGradients](../basic_api.rst#xsarsea.gradients.PlotGradients) that can be used to draw the circular histogram at mouse tap. (needs a live notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bfe478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# background image for vectorfield\n",
    "s0 = sar_ds['sigma0_detrend'].sel(pol='VV')\n",
    "hv_img = rasterize(hv.Image(s0, kdims=['sample', 'line']).opts(cmap='gray',clim=(0,np.nanpercentile(s0,95))))\n",
    "\n",
    "\n",
    "plot_mean_smooth = xsarsea.gradients.PlotGradients(hist_mean_smooth)\n",
    "\n",
    "# get vectorfield, with mouse tap activated\n",
    "hv_vf = plot_mean_smooth.vectorfield(tap=True)\n",
    "\n",
    "# connect mouse to histogram\n",
    "hv_hist = plot_mean_smooth.mouse_histogram()\n",
    "\n",
    "# notebook dynamic output\n",
    "hv_hist + hv_img * hv_vf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71180ae6",
   "metadata": {},
   "source": [
    "`hist_mean_smooth` was smoothed. Let's try `hist_smooth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07398ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_smooth = xsarsea.gradients.PlotGradients(hist_smooth)\n",
    "hv_vf = plot_smooth.vectorfield()\n",
    "hv_hist = plot_smooth.mouse_histogram()\n",
    "hv_hist + (hv_img * hv_vf).opts(legend_position='right', frame_width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aedc0df",
   "metadata": {},
   "source": [
    "Using `source` keyword for `mouse_histogram`, we can link several histrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfdb787",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_raw = xsarsea.gradients.PlotGradients(hist)\n",
    "plot_mean = xsarsea.gradients.PlotGradients(hist_mean)\n",
    "hv_vf = plot_smooth.vectorfield()\n",
    "\n",
    "hist_smooth_mean = hist_smooth.mean(['downscale_factor','window_size'])\n",
    "plot_smooth_mean = xsarsea.gradients.PlotGradients(hist_smooth_mean)\n",
    "\n",
    "gridspace = hv.GridSpace(kdims=['smooth','mean'])\n",
    "gridspace[(False,False)] = plot_smooth.mouse_histogram(source=plot_raw)\n",
    "gridspace[(True,False)] = plot_smooth.mouse_histogram()\n",
    "gridspace[(True,True)] = plot_smooth.mouse_histogram(source=plot_mean_smooth)\n",
    "gridspace[(False,True)] = plot_smooth.mouse_histogram(source=plot_mean)\n",
    "#gridspace[(False,True)] = plot_smooth.mouse_histogram(source=plot_smooth_mean)\n",
    "\n",
    "\n",
    "gridspace.opts(plot_size=(200,200)) + (hv_img * hv_vf).opts(legend_position='right', frame_height=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
